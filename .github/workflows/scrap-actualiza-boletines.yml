name: scrap-actualiza-boletines
run-name: Scrapea boletines (actualiza)
on:
  workflow_dispatch: # Manual
  schedule: # Run the action on a cron schedule
    - cron: '0 0 * * 5'   # Actualizamos los boletines todos los viernes

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
      with:
        persist-credentials: false # otherwise, the token used is the GITHUB_TOKEN, instead of your personal access token.
        fetch-depth: 0 # otherwise, there would be errors pushing refs to the destination repository.

    - name: Install pip requirements # Instalamos las librerias de python que usamos.
      run: |
        pip install -r update/requirements.txt

    - name: Actualiza boletines
      run: |
        python3 update/cacheBoletines.py

    - name: Commit files # Hacemos commit de los cambios.
      run: |
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git add .
        git commit -a -m "Auto scrapping"
        
    - name: Push changes # Y push - que a su vez triggea la accion de Pages.
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        branch: ${{ github.ref }}